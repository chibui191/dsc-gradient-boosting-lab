{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll learn how to use both Adaboost and Gradient Boosting classifiers from scikit-learn!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Use AdaBoost to make predictions on a dataset \n",
    "- Use Gradient Boosting to make predictions on a dataset \n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lab, we'll learn how to use boosting algorithms to make classifications on the [Pima Indians Dataset](http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.names). You will find the data stored in the file `'pima-indians-diabetes.csv'`. Our goal is to use boosting algorithms to determine whether a person has diabetes. Let's get started!\n",
    "\n",
    "We'll begin by importing everything we need for this lab. Run cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use Pandas to import the data stored in `'pima-indians-diabetes.csv'` and store it in a DataFrame. Print the first five rows to inspect the data we've imported and ensure everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('pima-indians-diabetes.csv')\n",
    "\n",
    "# Print the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, exploration, and preprocessing\n",
    "\n",
    "The target we're trying to predict is the `'Outcome'` column. A `1` denotes a patient with diabetes. \n",
    "\n",
    "By now, you're quite familiar with exploring and preprocessing a dataset.  \n",
    "\n",
    "In the following cells:\n",
    "\n",
    "* Check for missing values and deal with them as you see fit (if any exist) \n",
    "* Count the number of patients with and without diabetes in this dataset \n",
    "* Store the target column in a separate variable and remove it from the dataset\n",
    "* Split the dataset into training and test sets, with a `test_size` of 0.25 and a `random_state` of 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  768.000000                768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885  \n",
       "std      7.884160                  0.331329   11.760232  \n",
       "min      0.000000                  0.078000   21.000000  \n",
       "25%     27.300000                  0.243750   24.000000  \n",
       "50%     32.000000                  0.372500   29.000000  \n",
       "75%     36.600000                  0.626250   41.000000  \n",
       "max     67.100000                  2.420000   81.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of patients with and without diabetes\n",
    "df.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.Outcome\n",
    "df = df.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "Now that we've explored the dataset, we're ready to fit some models!\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Instantiate an `AdaBoostClassifier` (set the `random_state` for 42)\n",
    "* Instantiate a `GradientBoostingClassifer` (set the `random_state` for 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an AdaBoostClassifier\n",
    "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Instantiate an GradientBoostingClassifier\n",
    "gbt_clf = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit the training data to both the classifiers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit AdaBoostClassifier\n",
    "adaboost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GradientBoostingClassifier\n",
    "gbt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use these models to predict labels on both the training and test sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost model predictions\n",
    "adaboost_train_preds = adaboost_clf.predict(X_train)\n",
    "adaboost_test_preds = adaboost_clf.predict(X_test)\n",
    "\n",
    "# GradientBoosting model predictions\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, complete the following function and use it to calculate the accuracy and f1-score for each model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.8350694444444444\n",
      "F1-Score: 0.7493403693931399\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.9409722222222222\n",
      "F1-Score: 0.9105263157894736\n",
      "\n",
      "Testing Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.7239583333333334\n",
      "F1-Score: 0.618705035971223\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.7447916666666666\n",
      "F1-Score: 0.6620689655172414\n"
     ]
    }
   ],
   "source": [
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "print(\"Training Metrics\")\n",
    "display_acc_and_f1_score(y_train, adaboost_train_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "print(\"Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test, adaboost_test_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go one step further and create a confusion matrix and classification report for each. Do so in the cell below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[96, 27],\n",
       "       [26, 43]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_confusion_matrix = confusion_matrix(y_test, adaboost_test_preds)\n",
    "adaboost_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95, 28],\n",
       "       [21, 48]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test, gbt_clf_test_preds)\n",
    "gbt_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78       123\n",
      "           1       0.61      0.62      0.62        69\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.70      0.70      0.70       192\n",
      "weighted avg       0.72      0.72      0.72       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_classification_report = classification_report(y_test, adaboost_test_preds)\n",
    "print(adaboost_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79       123\n",
      "           1       0.63      0.70      0.66        69\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.73      0.73      0.73       192\n",
      "weighted avg       0.75      0.74      0.75       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_classification_report = classification_report(y_test, gbt_clf_test_preds)\n",
    "print(gbt_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** How did the models perform? Interpret the evaluation metrics above to answer this question.\n",
    "\n",
    "Write your answer below this line:\n",
    "_______________________________________________________________________________________________________________________________\n",
    "Gradient Boosting appears to perform slightly better on Testing data (by 2%). However, it's worth noting that Gradient Boosting has an accuracy of 94% on training data, and only 74% on testing (which means a drop of approx. 20%), compared to only roughly 11% difference between the training & testing accuracy scores by Adaboost. This indicates that Gradient Boosting might be overfitting (more than Adaboost). \n",
    "\n",
    "Both models have higher 0's precision than 1's, which is likely due to the uneven distribution of 0s and 1s in the original dataset (500 entries for 0 and only 268 for 1). \n",
    " \n",
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    "As a final performance check, let's calculate the 5-fold cross-validated score for each model! \n",
    "\n",
    "Recall that to compute the cross-validation score, we need to pass in:\n",
    "\n",
    "* A classifier\n",
    "* All training data\n",
    "* All labels\n",
    "* The number of folds we want in our cross-validation score  \n",
    "\n",
    "Since we're computing cross-validation score, we'll want to pass in the entire dataset, as well as all of the labels. \n",
    "\n",
    "In the cells below, compute the mean cross validation score for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Adaboost Cross-Val Score (k=5):\n",
      "0.7631270690094218\n"
     ]
    }
   ],
   "source": [
    "ada_cv_score = cross_val_score(AdaBoostClassifier(random_state=42), \n",
    "                               df, target,\n",
    "                               cv=5)\n",
    "print('Mean Adaboost Cross-Val Score (k=5):')\n",
    "print((ada_cv_score).mean())\n",
    "# Expected Output: 0.7631270690094218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean GBT Cross-Val Score (k=5):\n",
      "0.7604702487055428\n"
     ]
    }
   ],
   "source": [
    "gbt_cv_score = cross_val_score(GradientBoostingClassifier(random_state=42), \n",
    "                               df, target,\n",
    "                               cv=5)\n",
    "print('Mean GBT Cross-Val Score (k=5):')\n",
    "print(gbt_cv_score.mean())\n",
    "# Expected Output: 0.7591715474068416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models didn't do poorly, but we could probably do a bit better by tuning some of the important parameters such as the **_Learning Rate_**. \n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we learned how to use scikit-learn's implementations of popular boosting algorithms such as AdaBoost and Gradient Boosted Trees to make classification predictions on a real-world dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
